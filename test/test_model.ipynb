{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGn0oCeZSOQsph30LpvPHJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7f53b41ebf9a452895e0fedcdf76dced":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f51a7b7263d445eb019e31668c1c8b2","IPY_MODEL_c18109ee06dc4a2bbfc0e19f228f25a8","IPY_MODEL_eaa2c4f5f6104417bbb0bb4e7a2c3d43"],"layout":"IPY_MODEL_4f2ec8b52a5a4f93b792ac784d818c1e"}},"0f51a7b7263d445eb019e31668c1c8b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7b9cc6fd40e4a2b96046e2521a77d04","placeholder":"​","style":"IPY_MODEL_ff31e2fd55a04e0ab6ce8c11bc56c0ee","value":"tokenizer_config.json: 100%"}},"c18109ee06dc4a2bbfc0e19f228f25a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5577598e56224243a92de46d856c9ec1","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e04e70e46204bb3830d726aed2cf303","value":48}},"eaa2c4f5f6104417bbb0bb4e7a2c3d43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a626a3d33c5446ab5c369bc45fe4153","placeholder":"​","style":"IPY_MODEL_53d9dfc7d79c4a209cb9aa0ab08891c5","value":" 48.0/48.0 [00:00&lt;00:00, 737B/s]"}},"4f2ec8b52a5a4f93b792ac784d818c1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7b9cc6fd40e4a2b96046e2521a77d04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff31e2fd55a04e0ab6ce8c11bc56c0ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5577598e56224243a92de46d856c9ec1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e04e70e46204bb3830d726aed2cf303":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a626a3d33c5446ab5c369bc45fe4153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d9dfc7d79c4a209cb9aa0ab08891c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82543fa886ed4b74a4c49d473103b763":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17bc15b7127c4cb799737f1952461086","IPY_MODEL_6f8344a776e34f0586ebe8babb2b1440","IPY_MODEL_50f736b37ca84f69b37cf26c8aff7252"],"layout":"IPY_MODEL_28bab0b3206a41b496b8661d4505cfcc"}},"17bc15b7127c4cb799737f1952461086":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_368c9d15974049dd96d9b30666f48d1a","placeholder":"​","style":"IPY_MODEL_f3b1ee394d5f4592b6812a034ed86de8","value":"vocab.txt: 100%"}},"6f8344a776e34f0586ebe8babb2b1440":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dbf3f60fe35482eb2fde0e55f5a4e64","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce93ef4f501d4f958e87aac64af3ac9d","value":231508}},"50f736b37ca84f69b37cf26c8aff7252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_822288405b47408496ca54bf89fa3d31","placeholder":"​","style":"IPY_MODEL_313420bb9c42499fbb66310bb6663716","value":" 232k/232k [00:00&lt;00:00, 2.16MB/s]"}},"28bab0b3206a41b496b8661d4505cfcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"368c9d15974049dd96d9b30666f48d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3b1ee394d5f4592b6812a034ed86de8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0dbf3f60fe35482eb2fde0e55f5a4e64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce93ef4f501d4f958e87aac64af3ac9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"822288405b47408496ca54bf89fa3d31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"313420bb9c42499fbb66310bb6663716":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dca010dddec4085a99a2f17e2c8768b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07f1182675e2470b91bb374ae90e066a","IPY_MODEL_02b0a7e685234399aea79c3666117282","IPY_MODEL_1367edc11718440fa7245ded8924471f"],"layout":"IPY_MODEL_e9c461261e7d471793f310477fe71e90"}},"07f1182675e2470b91bb374ae90e066a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_695e6c95f6b346db9b42e05053fad59e","placeholder":"​","style":"IPY_MODEL_3646189190c148c1921df7434f1d374a","value":"tokenizer.json: 100%"}},"02b0a7e685234399aea79c3666117282":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39e6652946364f1a96f12062499955a8","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f95e5f9f0584ff7972aab78aeaaa2a5","value":466062}},"1367edc11718440fa7245ded8924471f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdb7beb464394defabaf20b9f483506b","placeholder":"​","style":"IPY_MODEL_6a66d8afa48f47418e838149be7ca271","value":" 466k/466k [00:00&lt;00:00, 10.9MB/s]"}},"e9c461261e7d471793f310477fe71e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"695e6c95f6b346db9b42e05053fad59e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3646189190c148c1921df7434f1d374a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39e6652946364f1a96f12062499955a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f95e5f9f0584ff7972aab78aeaaa2a5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fdb7beb464394defabaf20b9f483506b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a66d8afa48f47418e838149be7ca271":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c5c2096df194ab6ade1a76ff57480c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bbcab4ff0c04d679acf992512b3d8cb","IPY_MODEL_7856fe84f0864f1bbf532675aa3d7eb1","IPY_MODEL_cb3ab4bde0e549f091e3486c7f57a63c"],"layout":"IPY_MODEL_6d5b9825814a4bac8da584ecba98c938"}},"2bbcab4ff0c04d679acf992512b3d8cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_866df1cd71ae484d8a068447a30a408b","placeholder":"​","style":"IPY_MODEL_e3641c162d7e482186d2875972fb80fa","value":"config.json: 100%"}},"7856fe84f0864f1bbf532675aa3d7eb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cdc34d3a4b74b50ba1d662f812f1670","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81d08b37acb14dbf9d724da00edb3ee9","value":570}},"cb3ab4bde0e549f091e3486c7f57a63c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c88743072e74830958df025e170f882","placeholder":"​","style":"IPY_MODEL_7b1879ea046648618644319c40d11ad5","value":" 570/570 [00:00&lt;00:00, 3.60kB/s]"}},"6d5b9825814a4bac8da584ecba98c938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866df1cd71ae484d8a068447a30a408b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3641c162d7e482186d2875972fb80fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cdc34d3a4b74b50ba1d662f812f1670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d08b37acb14dbf9d724da00edb3ee9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c88743072e74830958df025e170f882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b1879ea046648618644319c40d11ad5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02088e5f3a7b4ed9b1501fb3da697e66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75555de27df243e1998506179485b0aa","IPY_MODEL_9592cf7a3fd244e5b55a68a9ba880c96","IPY_MODEL_41424c9d97654e91b5aee705a75d43f3"],"layout":"IPY_MODEL_a077ddb6f6c24b17af098b4c67539afd"}},"75555de27df243e1998506179485b0aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fcd525c9dc24be48792f125d2482a7b","placeholder":"​","style":"IPY_MODEL_eb8709ee9c1441c39525b55f65854c72","value":"model.safetensors: 100%"}},"9592cf7a3fd244e5b55a68a9ba880c96":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69eedb6db2574755b5659f70020fe5f5","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d398a0b4391464394f8c6a8a36893f1","value":440449768}},"41424c9d97654e91b5aee705a75d43f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68943b6f90b7472e93dac3016927ebae","placeholder":"​","style":"IPY_MODEL_f1e57e2dae8247859cb2b4f877478d6c","value":" 440M/440M [00:04&lt;00:00, 143MB/s]"}},"a077ddb6f6c24b17af098b4c67539afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fcd525c9dc24be48792f125d2482a7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb8709ee9c1441c39525b55f65854c72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69eedb6db2574755b5659f70020fe5f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d398a0b4391464394f8c6a8a36893f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68943b6f90b7472e93dac3016927ebae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e57e2dae8247859cb2b4f877478d6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers rake-nltk nltk sumy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itHVsRryXK33","executionInfo":{"status":"ok","timestamp":1729070178898,"user_tz":-120,"elapsed":19023,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"0fee453e-1a40-45bb-c8ce-ac9c541d6294"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting rake-nltk\n","  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Collecting sumy\n","  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Collecting docopt<0.7,>=0.6.1 (from sumy)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting breadability>=0.1.20 (from sumy)\n","  Downloading breadability-0.1.20.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pycountry>=18.2.23 (from sumy)\n","  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n","Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n","Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: breadability, docopt\n","  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21691 sha256=d2ce63c175f1d474ad902628c914f95eabe9676ed15b3f73d31461dbee7204b9\n","  Stored in directory: /root/.cache/pip/wheels/64/22/90/b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=f4fa8b0b5611ed1de284c0fedf72c1f10b1f7ecaf9e679b7043880b8317cff11\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built breadability docopt\n","Installing collected packages: docopt, pycountry, breadability, sumy, rake-nltk\n","Successfully installed breadability-0.1.20 docopt-0.6.2 pycountry-24.6.1 rake-nltk-1.0.6 sumy-0.11.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4GQ1XUhL5gH","executionInfo":{"status":"ok","timestamp":1729070208180,"user_tz":-120,"elapsed":29286,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"3cb5faee-b084-4c96-cc10-736ca8164efb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import nltk\n","import re\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from sklearn.metrics import classification_report, accuracy_score\n","from nltk.corpus import stopwords\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer as SumyTokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","from rake_nltk import Rake\n","from transformers import BertTokenizer"],"metadata":{"id":"0rJKxP4yMQw9","executionInfo":{"status":"ok","timestamp":1729069105166,"user_tz":-120,"elapsed":32691,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Скрипт для очищення коментаря\n","\n","переробити під інпут тексту"],"metadata":{"id":"f0i9JnjXYSJX"}},{"cell_type":"code","source":["name_df = \"test/test\""],"metadata":{"id":"sEjZkCrL-JQS","executionInfo":{"status":"ok","timestamp":1729069105167,"user_tz":-120,"elapsed":7,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Завантаження даних\n","test_labels_df = pd.read_csv('/content/drive/MyDrive/data/test_labels/test_labels.csv')\n","test_df_path = f'/content/drive/MyDrive/data/{name_df}.csv'\n","test_df = pd.read_csv(test_df_path)\n","\n","# Об'єднання датафреймів та видалення рядків з -1\n","merged_df = pd.merge(test_df, test_labels_df, on='id')\n","merged_df = merged_df[~(merged_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']] == -1).any(axis=1)]\n","merged_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhGVN9zzsXGU","executionInfo":{"status":"ok","timestamp":1729069110654,"user_tz":-120,"elapsed":5494,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"832fd9c5-8ada-4b74-d005-2e13afcc0704"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(63978, 8)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["\n","# Завантажте токенізатор punkt\n","nltk.download('punkt')\n","\n","# Завантаження стоп-слів для RAKE\n","nltk.download('stopwords')\n","\n","# Ініціалізація токенайзера BERT\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Функція для очищення тексту від цифр, знаків і спеціальних символів, крім ком і крапок\n","def clean_text_advanced(text):\n","\n","    # Приводимо текст до нижнього регістру\n","    text = text.lower()\n","    # видаляємо все що не англ.\n","    text = re.sub(r\"[^a-zA-Z.,\\s]\", \"\", text)\n","\n","    # Видаляємо всі цифри\n","    text = re.sub(r'\\d+', '', text)\n","\n","    # Видаляємо символи пунктуації, окрім коми і крапки\n","    text = re.sub(r'[^\\w\\s,.]', '', text)\n","\n","    # Видаляємо зайві символи нового рядка і замінюємо їх на пробіли\n","    text = text.replace('\\n', ' ')\n","\n","    # Видаляємо зайві пробіли\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","\n","    # Видаляємо слова, довжина яких більше 40 символів\n","    text =  re.sub(r'\\S{40,}', '', text)\n","\n","    # Регулярний вираз для знаходження посилань\n","    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n","    text = re.sub(url_pattern, '', text)\n","\n","    # Видалення фраз, що повторюються більше двох разів підряд\n","    text = re.sub(r'(\\b\\w+\\b)(\\s+\\1)+', r'\\1', text)\n","\n","    # Видалення повторюваних речень більше ніж два рази підряд\n","    text = re.sub(r'(\\b.+?\\b)(\\s*\\1)+', r'\\1', text)\n","\n","   # Видалення повторюваних однакових літер (наприклад, AAAAAAA)\n","    text = re.sub(r'(.)\\1{2,}', r'\\1', text)  # Заміна 3 або більше однакових букв\n","\n","    # Видалення повторюваних шаблонів, де кожна друга літера інша (наприклад, XAXAXA)\n","    text = re.sub(r'(.)(.)\\1\\2{2,}', r'\\1\\2', text)  # Заміна патернів повторів XAXAXA, XAXAXXAXX\n","\n","    # Видаляємо повторювані послідовності сміху (ahahah, muahahah)\n","    text = re.sub(r'(ha|ah|mu|lol){2,}', '', text)\n","\n","    # Видаляємо повторювані фрази більше ніж двічі (наприклад, \"i hate you\" або \"die die die\")\n","    text = re.sub(r'(\\b\\w+\\b)(\\s+\\1){2,}', r'\\1', text)\n","\n","    # Видаляємо повторення фраз (двох і більше разів)\n","    text = re.sub(r'\\b(\\w+\\b(?:\\s+\\w+\\b){0,5})\\s*(\\1\\s*)+', r'\\1', text)\n","\n","    # Видаляємо довгі повторення одного і того ж слова (більше 2 разів)\n","    text = re.sub(r'\\b(\\w+)\\s+\\1\\s+\\1(?:\\s+\\1)+', r'\\1', text)\n","\n","    # Видаляємо довгі рядки сміху (ahahaha, lol, muahaha) - залишаємо не більше 1-2 повторів\n","    text = re.sub(r'(\\b(?:ha|ah|lol|mu|muah)+\\b(?:\\s*\\b(?:ha|ah|lol|mu|muah)+\\b){2,})', r'\\1', text)\n","\n","    return text\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373,"referenced_widgets":["7f53b41ebf9a452895e0fedcdf76dced","0f51a7b7263d445eb019e31668c1c8b2","c18109ee06dc4a2bbfc0e19f228f25a8","eaa2c4f5f6104417bbb0bb4e7a2c3d43","4f2ec8b52a5a4f93b792ac784d818c1e","e7b9cc6fd40e4a2b96046e2521a77d04","ff31e2fd55a04e0ab6ce8c11bc56c0ee","5577598e56224243a92de46d856c9ec1","2e04e70e46204bb3830d726aed2cf303","9a626a3d33c5446ab5c369bc45fe4153","53d9dfc7d79c4a209cb9aa0ab08891c5","82543fa886ed4b74a4c49d473103b763","17bc15b7127c4cb799737f1952461086","6f8344a776e34f0586ebe8babb2b1440","50f736b37ca84f69b37cf26c8aff7252","28bab0b3206a41b496b8661d4505cfcc","368c9d15974049dd96d9b30666f48d1a","f3b1ee394d5f4592b6812a034ed86de8","0dbf3f60fe35482eb2fde0e55f5a4e64","ce93ef4f501d4f958e87aac64af3ac9d","822288405b47408496ca54bf89fa3d31","313420bb9c42499fbb66310bb6663716","6dca010dddec4085a99a2f17e2c8768b","07f1182675e2470b91bb374ae90e066a","02b0a7e685234399aea79c3666117282","1367edc11718440fa7245ded8924471f","e9c461261e7d471793f310477fe71e90","695e6c95f6b346db9b42e05053fad59e","3646189190c148c1921df7434f1d374a","39e6652946364f1a96f12062499955a8","5f95e5f9f0584ff7972aab78aeaaa2a5","fdb7beb464394defabaf20b9f483506b","6a66d8afa48f47418e838149be7ca271","2c5c2096df194ab6ade1a76ff57480c1","2bbcab4ff0c04d679acf992512b3d8cb","7856fe84f0864f1bbf532675aa3d7eb1","cb3ab4bde0e549f091e3486c7f57a63c","6d5b9825814a4bac8da584ecba98c938","866df1cd71ae484d8a068447a30a408b","e3641c162d7e482186d2875972fb80fa","3cdc34d3a4b74b50ba1d662f812f1670","81d08b37acb14dbf9d724da00edb3ee9","7c88743072e74830958df025e170f882","7b1879ea046648618644319c40d11ad5"]},"id":"zNKFDc9nRAmG","outputId":"ca79fc2a-4313-43c3-cb04-7931014808f9","executionInfo":{"status":"ok","timestamp":1729069114574,"user_tz":-120,"elapsed":3925,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f53b41ebf9a452895e0fedcdf76dced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82543fa886ed4b74a4c49d473103b763"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dca010dddec4085a99a2f17e2c8768b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c5c2096df194ab6ade1a76ff57480c1"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# клауд скорочення коментаря"],"metadata":{"id":"aA4ax7Y57C9v"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.probability import FreqDist\n","import numpy as np\n","\n","test_claud = merged_df\n","\n","class TextSummarizer:\n","    def __init__(self):\n","        # Завантажуємо необхідні ресурси NLTK\n","        nltk.download('punkt')\n","        nltk.download('stopwords')\n","        self.stop_words = stopwords.words('english')\n","\n","    def preprocess_text(self, text):\n","        # Розбиваємо текст на речення\n","        sentences = sent_tokenize(text)\n","\n","        # Токенізація та видалення стоп-слів\n","        word_tokens = []\n","        for sentence in sentences:\n","            words = word_tokenize(sentence.lower())\n","            words = [w for w in words if w.isalnum() and w not in self.stop_words]\n","            word_tokens.extend(words)\n","\n","        return sentences, word_tokens\n","\n","    def get_sentence_scores(self, sentences, word_tokens):\n","        # Створюємо частотний розподіл слів\n","        freq_dist = FreqDist(word_tokens)\n","\n","        # Обчислюємо оцінки для кожного речення\n","        sentence_scores = {}\n","        for i, sentence in enumerate(sentences):\n","            words = word_tokenize(sentence.lower())\n","            words = [w for w in words if w.isalnum()]\n","            score = sum([freq_dist[word] for word in words if word not in self.stop_words])\n","            sentence_scores[i] = score / len(words) if words else 0\n","\n","        return sentence_scores\n","\n","    def summarize(self, text, target_length=512):\n","\n","        # видаляємо зайве з коментаря\n","        text = clean_text_advanced(text)\n","\n","\n","        # Попередня обробка тексту\n","        sentences, word_tokens = self.preprocess_text(text)\n","\n","        # Отримуємо оцінки речень\n","        sentence_scores = self.get_sentence_scores(sentences, word_tokens)\n","\n","        # Сортуємо речення за оцінками\n","        sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","        # Вибираємо найважливіші речення\n","        selected_sentences = []\n","        current_length = 0\n","\n","        for sentence_idx, _ in sorted_sentences:\n","            sentence = sentences[sentence_idx]\n","            sentence_length = len(sentence)\n","\n","            if current_length + sentence_length <= target_length:\n","                selected_sentences.append((sentence_idx, sentence))\n","                current_length += sentence_length\n","            else:\n","                break\n","\n","        # Відновлюємо оригінальний порядок речень\n","        summary = ' '.join([sentence for _, sentence in sorted(selected_sentences)])\n","\n","        return summary\n","\n","# Приклад використання\n","summarizer = TextSummarizer()\n","\n","# Застосовуємо метод summarize до кожного коментаря у колонці 'comment_text'\n","test_claud['comment_text'] = test_claud['comment_text'].apply(lambda x: summarizer.summarize(x, target_length=512))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBChyiNl2sE2","executionInfo":{"status":"ok","timestamp":1729069555305,"user_tz":-120,"elapsed":254756,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"c8e3cf7a-ae39-4cbe-eda2-9349f723913f"},"execution_count":7,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["test_claud.to_csv('/content/drive/MyDrive/data/test_claud.csv', index=False)"],"metadata":{"id":"uVhv7pPXjQTP","executionInfo":{"status":"ok","timestamp":1729069611040,"user_tz":-120,"elapsed":922,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Вибір перших 100 рядків з merged_df\n","sample_df = test_claud.head(1000)\n"],"metadata":{"id":"l4mwtP1BRAfx","executionInfo":{"status":"ok","timestamp":1729027963558,"user_tz":-120,"elapsed":353,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["sample_df.shape"],"metadata":{"id":"npeZ7nhKRAix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729027965938,"user_tz":-120,"elapsed":346,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"c0a7a613-536b-4385-db4c-96a7d9594826"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 8)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/data/test_claud.csv')"],"metadata":{"id":"vOrbeBepxOfp","executionInfo":{"status":"ok","timestamp":1729070220756,"user_tz":-120,"elapsed":2267,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Видаляємо рядки з відсутніми коментарями\n","data = data.dropna(subset=['comment_text'])\n","\n","# Перевірка кількості рядків після видалення\n","print(f\"Залишилося рядків: {len(data)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MW3243qom2PL","executionInfo":{"status":"ok","timestamp":1729071433045,"user_tz":-120,"elapsed":450,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"b2e3fc16-b226-438a-b5eb-2a6143ccc6a8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Залишилося рядків: 63477\n"]}]},{"cell_type":"code","source":["# Підготовка даних: тексти і мітки (labels)\n","texts = data['comment_text'].values\n","labels = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"uljfkIJalUfI","executionInfo":{"status":"ok","timestamp":1729072929114,"user_tz":-120,"elapsed":515814,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"71b804ff-467e-49f7-f73b-531ec8299f6a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-16-b6dd8169b155>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load(model_path, map_location=device)\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Evaluating: 100%|██████████| 1984/1984 [07:29<00:00,  4.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8662\n","Precision: 0.5672\n","Recall: 0.6535\n","F1 Score: 0.5890\n"]}]},{"cell_type":"markdown","source":["# для моделі з розширенням .pt"],"metadata":{"id":"wScQOuzi5psM"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","import numpy as np\n","import os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Перевірка доступності GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Шлях до моделі\n","model_path = \"/content/drive/My Drive/bert_toxicity_full_model.pt\"\n","\n","# Перевірка існування файлу\n","if not os.path.exists(model_path):\n","    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n","\n","# Завантаження моделі\n","try:\n","    # Спроба завантажити як повну модель\n","    model = torch.load(model_path, map_location=device)\n","except:\n","    try:\n","        # Спроба завантажити як state_dict\n","        model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n","        state_dict = torch.load(model_path, map_location=device)\n","        model.load_state_dict(state_dict)\n","    except Exception as e:\n","        print(f\"Error loading model: {e}\")\n","        print(\"Trying to load model without strict parameter...\")\n","        try:\n","            # Спроба завантажити без строгої відповідності ключів\n","            model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n","            state_dict = torch.load(model_path, map_location=device)\n","            model.load_state_dict(state_dict, strict=False)\n","        except Exception as e:\n","            raise Exception(f\"Failed to load model: {e}\")\n","\n","model.to(device)\n","model.eval()\n","\n","# Завантаження токенізатора\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Підготовка даних\n","max_length = 128\n","\n","def prepare_data(texts):\n","    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n","    return encodings\n","\n","# Створення DataLoader\n","batch_size = 32\n","encodings = prepare_data(texts)\n","dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels, dtype=torch.float))\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","# Функція для отримання передбачень\n","def get_predictions(model, dataloader):\n","    predictions = []\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n","            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            predictions.append(torch.sigmoid(logits).cpu().numpy())\n","    return np.vstack(predictions)\n","\n","# Отримання передбачень\n","predictions = get_predictions(model, dataloader)\n","\n","# Перетворення ймовірностей у бінарні мітки\n","binary_predictions = (predictions > 0.5).astype(int)\n","\n","# Функція оцінки результатів для мульти-лейбл класифікації\n","def evaluate_multilabel_results(true_labels, predicted_labels):\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    precision = precision_score(true_labels, predicted_labels, average='micro')\n","    recall = recall_score(true_labels, predicted_labels, average='micro')\n","    f1 = f1_score(true_labels, predicted_labels, average='micro')\n","\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","\n","    # Оцінка по кожному класу\n","    class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","    for i, class_name in enumerate(class_names):\n","        precision = precision_score(true_labels[:, i], predicted_labels[:, i])\n","        recall = recall_score(true_labels[:, i], predicted_labels[:, i])\n","        f1 = f1_score(true_labels[:, i], predicted_labels[:, i])\n","        print(f\"\\n{class_name}:\")\n","        print(f\"Precision: {precision:.4f}\")\n","        print(f\"Recall: {recall:.4f}\")\n","        print(f\"F1 Score: {f1:.4f}\")\n","\n","# Оцінка результатів\n","evaluate_multilabel_results(labels, binary_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-T4FNH-lUbr","executionInfo":{"status":"ok","timestamp":1729073788447,"user_tz":-120,"elapsed":516436,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"b3c8c126-9b0f-4ee8-c0c4-013cd6858f92"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-17-e3f1d303b192>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load(model_path, map_location=device)\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Evaluating: 100%|██████████| 1984/1984 [07:29<00:00,  4.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8662\n","Precision: 0.5579\n","Recall: 0.8126\n","F1 Score: 0.6616\n","\n","toxic:\n","Precision: 0.5238\n","Recall: 0.9056\n","F1 Score: 0.6637\n","\n","severe_toxic:\n","Precision: 0.3252\n","Recall: 0.4793\n","F1 Score: 0.3875\n","\n","obscene:\n","Precision: 0.6208\n","Recall: 0.7732\n","F1 Score: 0.6887\n","\n","threat:\n","Precision: 0.6207\n","Recall: 0.4306\n","F1 Score: 0.5085\n","\n","insult:\n","Precision: 0.5783\n","Recall: 0.8083\n","F1 Score: 0.6743\n","\n","identity_hate:\n","Precision: 0.7341\n","Recall: 0.5241\n","F1 Score: 0.6116\n"]}]},{"cell_type":"markdown","source":["# для моделі з розширенням .pth"],"metadata":{"id":"mcB7q-ju5e8w"}},{"cell_type":"code","source":["import torch\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","import numpy as np\n","import os\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Перевірка доступності GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Шлях до моделі\n","model_path = \"/content/drive/MyDrive/toxicity_model/toxicity_model.pth\"\n","\n","# Перевірка існування файлу\n","if not os.path.exists(model_path):\n","    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n","\n","# Завантаження моделі\n","try:\n","    # Спочатку створюємо модель з архітектурою BERT\n","    model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6)\n","\n","    # Завантажуємо стан моделі\n","    state_dict = torch.load(model_path, map_location=device)\n","\n","    # Перевіряємо, чи завантажений об'єкт є словником стану\n","    if isinstance(state_dict, dict):\n","        # Якщо це словник стану\n","        if 'state_dict' in state_dict:\n","            # Якщо стан знаходиться під ключем 'state_dict'\n","            model.load_state_dict(state_dict['state_dict'])\n","        else:\n","            # Якщо це просто словник стану\n","            model.load_state_dict(state_dict)\n","    elif isinstance(state_dict, BertForSequenceClassification):\n","        # Якщо це повна модель\n","        model = state_dict\n","    else:\n","        raise TypeError(\"Unexpected type of loaded object\")\n","\n","except Exception as e:\n","    raise Exception(f\"Failed to load model: {e}\")\n","\n","model.to(device)\n","model.eval()\n","\n","# Завантаження токенізатора\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","# Підготовка даних\n","max_length = 128\n","\n","def prepare_data(texts):\n","    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n","    return encodings\n","\n","# Створення DataLoader\n","batch_size = 32\n","encodings = prepare_data(texts)\n","dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels, dtype=torch.float))\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n","\n","# Функція для отримання передбачень\n","def get_predictions(model, dataloader):\n","    predictions = []\n","    with torch.no_grad():\n","        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n","            input_ids, attention_mask, _ = [b.to(device) for b in batch]\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            predictions.append(torch.sigmoid(logits).cpu().numpy())\n","    return np.vstack(predictions)\n","\n","# Отримання передбачень\n","predictions = get_predictions(model, dataloader)\n","\n","# Перетворення ймовірностей у бінарні мітки\n","binary_predictions = (predictions > 0.5).astype(int)\n","\n","# Функція оцінки результатів для мульти-лейбл класифікації\n","def evaluate_multilabel_results(true_labels, predicted_labels):\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    precision = precision_score(true_labels, predicted_labels, average='micro')\n","    recall = recall_score(true_labels, predicted_labels, average='micro')\n","    f1 = f1_score(true_labels, predicted_labels, average='micro')\n","\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","\n","    # Оцінка по кожному класу\n","    class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n","    for i, class_name in enumerate(class_names):\n","        precision = precision_score(true_labels[:, i], predicted_labels[:, i])\n","        recall = recall_score(true_labels[:, i], predicted_labels[:, i])\n","        f1 = f1_score(true_labels[:, i], predicted_labels[:, i])\n","        print(f\"\\n{class_name}:\")\n","        print(f\"Precision: {precision:.4f}\")\n","        print(f\"Recall: {recall:.4f}\")\n","        print(f\"F1 Score: {f1:.4f}\")\n","\n","# Оцінка результатів\n","evaluate_multilabel_results(labels, binary_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbYx7NGhlUYT","outputId":"5fcb081c-e659-44b7-f323-54f989342abf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","<ipython-input-19-3cacb65a84ed>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(model_path, map_location=device)\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Evaluating:  46%|████▌     | 909/1984 [03:29<04:02,  4.42it/s]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"149v7KyglUVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YGP3WgYulUS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3OvTxBmelUQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tUNTlQr3lUNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"awrSdnuDlULJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vqA4KYk0lUIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"80WhFC98lUFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qrktwxG4lUCp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import classification_report, accuracy_score\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification\n","\n","# Шлях до збереженої моделі\n","MODEL_PATH = '/content/drive/My Drive/toxicity_model/toxicity_model.pth'"],"metadata":{"id":"52DGF12aPImX","executionInfo":{"status":"ok","timestamp":1729032265481,"user_tz":-120,"elapsed":352,"user":{"displayName":"Maksim","userId":"18160881988083746316"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Підготовка даних\n","texts = data['comment_text'].values\n","labels = data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n","print(\"Дані підготовлені\")\n","\n","# Клас для створення набору даних\n","class ToxicityDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.FloatTensor(label)\n","        }\n","\n","# Визначення пристрою - тільки CPU\n","device = torch.device('cpu')\n","print(f\"Використовується пристрій: {device}\")\n","\n","# Завантаження збережених ваг моделі\n","state_dict = torch.load(MODEL_PATH, map_location=device)\n","\n","# Ініціалізація моделі з правильною кількістю міток\n","num_labels = len(state_dict['classifier.weight'])\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n","\n","# Завантаження збережених ваг у модель\n","model.load_state_dict(state_dict)\n","model.to(device)\n","model.eval()\n","\n","# Ініціалізація токенізатора\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Створення тестового набору даних та завантажувача\n","test_dataset = ToxicityDataset(texts, labels, tokenizer, max_len=256)\n","test_loader = DataLoader(test_dataset, batch_size=16)\n","\n","# Функція для отримання прогнозів\n","def get_predictions(model, data_loader):\n","    model.eval()\n","    predictions = []\n","    real_values = []\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            inputs = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(inputs, attention_mask=attention_mask)\n","            preds = torch.sigmoid(outputs.logits)  # Сигмоїд для мульти-лейбл задач\n","            preds = (preds > 0.5).int()  # Встановлюємо поріг\n","\n","            predictions.append(preds)\n","            real_values.append(labels)\n","\n","    predictions = torch.cat(predictions).numpy()\n","    real_values = torch.cat(real_values).numpy()\n","    return predictions, real_values\n","\n","# Отримання прогнозів\n","print(\"Початок прогнозування...\")\n","y_pred, y_true = get_predictions(model, test_loader)\n","print(\"Прогнозування завершено\")\n","\n","# Виведення результатів\n","print(\"\\nРезультати класифікації:\")\n","print(classification_report(y_true, y_pred, target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], zero_division=0))\n","\n","# Додатково: обчислення загальної точності\n","accuracy = accuracy_score(y_true.flatten(), y_pred.flatten())\n","print(f\"\\nЗагальна точність: {accuracy:.4f}\")\n"],"metadata":{"id":"cC-CEZmZNMfr","colab":{"base_uri":"https://localhost:8080/","height":225,"referenced_widgets":["02088e5f3a7b4ed9b1501fb3da697e66","75555de27df243e1998506179485b0aa","9592cf7a3fd244e5b55a68a9ba880c96","41424c9d97654e91b5aee705a75d43f3","a077ddb6f6c24b17af098b4c67539afd","1fcd525c9dc24be48792f125d2482a7b","eb8709ee9c1441c39525b55f65854c72","69eedb6db2574755b5659f70020fe5f5","7d398a0b4391464394f8c6a8a36893f1","68943b6f90b7472e93dac3016927ebae","f1e57e2dae8247859cb2b4f877478d6c"]},"outputId":"1a677610-efa9-4dfe-ae5d-feedea6e3981"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Дані підготовлені\n","Використовується пристрій: cpu\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-11-7ac8428be9db>:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(MODEL_PATH, map_location=device)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02088e5f3a7b4ed9b1501fb3da697e66","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Початок прогнозування...\n"]}]}]}