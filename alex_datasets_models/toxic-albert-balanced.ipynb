{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9676466,"sourceType":"datasetVersion","datasetId":5914031},{"sourceId":9676662,"sourceType":"datasetVersion","datasetId":5913940}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ALBERT model trained on the `train_data_cleaned` dataset","metadata":{}},{"cell_type":"code","source":"!pip install torch\n!pip install transformers\n!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:36:55.358500Z","iopub.execute_input":"2024-10-21T12:36:55.358896Z","iopub.status.idle":"2024-10-21T12:37:30.232549Z","shell.execute_reply.started":"2024-10-21T12:36:55.358845Z","shell.execute_reply":"2024-10-21T12:37:30.231576Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import AlbertTokenizer, AlbertForSequenceClassification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:30.234575Z","iopub.execute_input":"2024-10-21T12:37:30.234946Z","iopub.status.idle":"2024-10-21T12:37:36.186983Z","shell.execute_reply.started":"2024-10-21T12:37:30.234912Z","shell.execute_reply":"2024-10-21T12:37:36.185959Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the dataset","metadata":{}},{"cell_type":"code","source":"# Path to a clean dataset\ndataset_path = '/kaggle/input/toxic-comments/train_data_cleaned.csv'\n\n# Load the dataset into a DataFrame\ndf_train = pd.read_csv(dataset_path)\n\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:36.188309Z","iopub.execute_input":"2024-10-21T12:37:36.188920Z","iopub.status.idle":"2024-10-21T12:37:37.498688Z","shell.execute_reply.started":"2024-10-21T12:37:36.188874Z","shell.execute_reply":"2024-10-21T12:37:37.497701Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  explanation why the edits made under my userna...      0   \n1  000103f0d9cfb60f  daww he matches this background colour im seem...      0   \n2  000113f07ec002fd  hey man, im really not trying to edit war. its...      0   \n3  0001b41b1c6bb37e  more i cant make any real suggestions on impro...      0   \n4  0001d958c54c6e35  you, sir, are my hero. any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  token_count  \n0             0        0       0       0              0           54  \n1             0        0       0       0              0           20  \n2             0        0       0       0              0           48  \n3             0        0       0       0              0          119  \n4             0        0       0       0              0           17  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>explanation why the edits made under my userna...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>daww he matches this background colour im seem...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>hey man, im really not trying to edit war. its...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>more i cant make any real suggestions on impro...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>you, sir, are my hero. any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.describe()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:37.501332Z","iopub.execute_input":"2024-10-21T12:37:37.501705Z","iopub.status.idle":"2024-10-21T12:37:37.555852Z","shell.execute_reply.started":"2024-10-21T12:37:37.501655Z","shell.execute_reply":"2024-10-21T12:37:37.554890Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"               toxic   severe_toxic        obscene         threat  \\\ncount  159571.000000  159571.000000  159571.000000  159571.000000   \nmean        0.095844       0.009996       0.052948       0.002996   \nstd         0.294379       0.099477       0.223931       0.054650   \nmin         0.000000       0.000000       0.000000       0.000000   \n25%         0.000000       0.000000       0.000000       0.000000   \n50%         0.000000       0.000000       0.000000       0.000000   \n75%         0.000000       0.000000       0.000000       0.000000   \nmax         1.000000       1.000000       1.000000       1.000000   \n\n              insult  identity_hate    token_count  \ncount  159571.000000  159571.000000  159571.000000  \nmean        0.049364       0.008805      79.119602  \nstd         0.216627       0.093420     114.629912  \nmin         0.000000       0.000000       0.000000  \n25%         0.000000       0.000000      20.000000  \n50%         0.000000       0.000000      43.000000  \n75%         0.000000       0.000000      89.000000  \nmax         1.000000       1.000000    1373.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n      <th>token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n      <td>159571.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.095844</td>\n      <td>0.009996</td>\n      <td>0.052948</td>\n      <td>0.002996</td>\n      <td>0.049364</td>\n      <td>0.008805</td>\n      <td>79.119602</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.294379</td>\n      <td>0.099477</td>\n      <td>0.223931</td>\n      <td>0.054650</td>\n      <td>0.216627</td>\n      <td>0.093420</td>\n      <td>114.629912</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>43.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>89.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1373.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:37.557278Z","iopub.execute_input":"2024-10-21T12:37:37.558007Z","iopub.status.idle":"2024-10-21T12:37:37.616105Z","shell.execute_reply.started":"2024-10-21T12:37:37.557957Z","shell.execute_reply":"2024-10-21T12:37:37.615059Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 159571 entries, 0 to 159570\nData columns (total 9 columns):\n #   Column         Non-Null Count   Dtype \n---  ------         --------------   ----- \n 0   id             159571 non-null  object\n 1   comment_text   159562 non-null  object\n 2   toxic          159571 non-null  int64 \n 3   severe_toxic   159571 non-null  int64 \n 4   obscene        159571 non-null  int64 \n 5   threat         159571 non-null  int64 \n 6   insult         159571 non-null  int64 \n 7   identity_hate  159571 non-null  int64 \n 8   token_count    159571 non-null  int64 \ndtypes: int64(7), object(2)\nmemory usage: 11.0+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check the number of labels for each class\ncolumn_labels = df_train.columns.tolist()[2:8]\nlabel_counts = df_train[column_labels].sum().sort_values(ascending=False)\n\nlabel_counts","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:37.617538Z","iopub.execute_input":"2024-10-21T12:37:37.617967Z","iopub.status.idle":"2024-10-21T12:37:37.632083Z","shell.execute_reply.started":"2024-10-21T12:37:37.617926Z","shell.execute_reply":"2024-10-21T12:37:37.630833Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"toxic            15294\nobscene           8449\ninsult            7877\nsevere_toxic      1595\nidentity_hate     1405\nthreat             478\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualizing the class distribution of the 'label' column\nplt.figure(figsize=(10, 6))\n\nax = sns.barplot(x=label_counts.index, y=label_counts.values, palette='pastel')\n\n# Add labels and title to the plot\nplt.xlabel('Labels')\nplt.ylabel('Number of Cases')\nplt.title('Distribution of Label Frequency')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:37.633454Z","iopub.execute_input":"2024-10-21T12:37:37.633849Z","iopub.status.idle":"2024-10-21T12:37:38.186101Z","shell.execute_reply.started":"2024-10-21T12:37:37.633807Z","shell.execute_reply":"2024-10-21T12:37:38.185148Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"The dataset shows a significant class imbalance across the different toxicity labels. For instance, the toxic class is represented by 15,294 examples, while the threat class has only 478 examples, making it highly underrepresented. Other categories such as severe toxic (1,595), identity hate (1,405), and insult (7,877) are also much smaller compared to the more frequent classes like toxic and obscene (8,449).\n\nThis imbalance could lead the model to favor the majority classes, which may result in poor performance when predicting minority classes. To address this issue, it will be important to apply class weights during the training process, specifically in the loss function. By assigning higher weights to the minority classes, the model will learn to focus more on these underrepresented categories, improving its ability to make accurate predictions across all toxicity levels.","metadata":{}},{"cell_type":"code","source":"# Split data into training and validation sets\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n    df_train['comment_text'],\n    df_train.iloc[:, 2:8],\n    test_size=0.20,\n    random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.187237Z","iopub.execute_input":"2024-10-21T12:37:38.187721Z","iopub.status.idle":"2024-10-21T12:37:38.218456Z","shell.execute_reply.started":"2024-10-21T12:37:38.187686Z","shell.execute_reply":"2024-10-21T12:37:38.217431Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(f'Training data shape: {train_data.shape}')\nprint(f'Training labels shape: {train_labels.shape}')\nprint(f'Validation data shape: {val_data.shape}')\nprint(f'Validation labels shape: {val_labels.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.220281Z","iopub.execute_input":"2024-10-21T12:37:38.220577Z","iopub.status.idle":"2024-10-21T12:37:38.226744Z","shell.execute_reply.started":"2024-10-21T12:37:38.220546Z","shell.execute_reply":"2024-10-21T12:37:38.225582Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training data shape: (127656,)\nTraining labels shape: (127656, 6)\nValidation data shape: (31915,)\nValidation labels shape: (31915, 6)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model preparation and training","metadata":{}},{"cell_type":"code","source":"# Token and Encode Function\ndef tokenize_and_encode(tokenizer, comments, labels, max_length=512):\n    # Initialize empty lists to store tokenized inputs and attention masks\n    input_ids = []\n    attention_masks = []\n    \n    # Iterate through each comment in the 'comments' list\n    for comment in comments:\n        # Tokenize and encode the comment using the ALBERT tokenizer\n        encoded_dict = tokenizer.encode_plus(\n            comment,\n            add_special_tokens=True,  # Add special tokens like [CLS] and [SEP]\n            max_length=max_length,\n            padding='max_length',  # Add padding to the maximum size\n            truncation=True,  # If the comment is longer than max_length, cut it off\n            return_attention_mask=True,  # Return attention mask to mask padded tokens\n            return_tensors='pt'  # Return PyTorch tensors\n        )\n        \n        # Append the tokenized input and attention mask to their respective lists\n        input_ids.append(encoded_dict['input_ids'].squeeze().tolist())\n        attention_masks.append(encoded_dict['attention_mask'].squeeze().tolist())\n    \n    # Convert to a PyTorch tensor\n    input_ids = torch.tensor(input_ids)\n    attention_masks = torch.tensor(attention_masks)\n    labels = torch.tensor(labels)\n    \n    # Return the tokenized inputs, attention masks, and labels as PyTorch tensors\n    return input_ids, attention_masks, labels","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.232213Z","iopub.execute_input":"2024-10-21T12:37:38.232569Z","iopub.status.idle":"2024-10-21T12:37:38.240860Z","shell.execute_reply.started":"2024-10-21T12:37:38.232536Z","shell.execute_reply":"2024-10-21T12:37:38.239570Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Token Initialization\ntokenizer = AlbertTokenizer.from_pretrained('/kaggle/input/albert-base-v2')","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.242875Z","iopub.execute_input":"2024-10-21T12:37:38.243292Z","iopub.status.idle":"2024-10-21T12:37:38.705358Z","shell.execute_reply.started":"2024-10-21T12:37:38.243244Z","shell.execute_reply":"2024-10-21T12:37:38.704208Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model Initialization\nmodel = AlbertForSequenceClassification.from_pretrained('/kaggle/input/albert-base-v2', num_labels=6)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.706855Z","iopub.execute_input":"2024-10-21T12:37:38.707253Z","iopub.status.idle":"2024-10-21T12:37:38.854710Z","shell.execute_reply.started":"2024-10-21T12:37:38.707210Z","shell.execute_reply":"2024-10-21T12:37:38.853808Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for NaN values in train_data\nprint(\"NaN values in train_data:\")\nprint(train_data.isnull().sum())\n\n# Drop rows with NaN values in train_data\ntrain_data_cleaned = train_data.dropna()\n\n# Filter train_labels to match the cleaned train_data\ntrain_labels_cleaned = train_labels.loc[train_data_cleaned.index]\n\n# Recheck for NaN values after cleaning\nprint(\"NaN values in train_data_cleaned:\")\nprint(train_data_cleaned.isnull().sum())\nprint(\"NaN values in train_labels_cleaned:\")\nprint(train_labels_cleaned.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.855965Z","iopub.execute_input":"2024-10-21T12:37:38.857770Z","iopub.status.idle":"2024-10-21T12:37:38.943551Z","shell.execute_reply.started":"2024-10-21T12:37:38.857722Z","shell.execute_reply":"2024-10-21T12:37:38.942544Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"NaN values in train_data:\n7\nNaN values in train_data_cleaned:\n0\nNaN values in train_labels_cleaned:\ntoxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for NaN values in val_data\nprint(\"NaN values in val_data:\")\nprint(val_data.isnull().sum())\n\n# Drop rows with NaN values in val_data\nval_data_cleaned = val_data.dropna()\n\n# Filter val_labels to match the cleaned val_data\nval_labels_cleaned = val_labels.loc[val_data_cleaned.index]\n\n# Recheck for NaN values after cleaning\nprint(\"NaN values in val_data_cleaned:\")\nprint(val_data_cleaned.isnull().sum())\nprint(\"NaN values in val_labels_cleaned:\")\nprint(val_labels_cleaned.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.944918Z","iopub.execute_input":"2024-10-21T12:37:38.945236Z","iopub.status.idle":"2024-10-21T12:37:38.971565Z","shell.execute_reply.started":"2024-10-21T12:37:38.945203Z","shell.execute_reply":"2024-10-21T12:37:38.970559Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"NaN values in val_data:\n2\nNaN values in val_data_cleaned:\n0\nNaN values in val_labels_cleaned:\ntoxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the device to GPU if available, otherwise use CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Check if CUDA is available\nif torch.cuda.is_available():\n    print(\"CUDA is available! The model will use the GPU.\")\nelse:\n    print(\"CUDA is not available. The model will use the CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:38.972699Z","iopub.execute_input":"2024-10-21T12:37:38.973000Z","iopub.status.idle":"2024-10-21T12:37:39.031881Z","shell.execute_reply.started":"2024-10-21T12:37:38.972969Z","shell.execute_reply":"2024-10-21T12:37:39.030583Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"CUDA is available! The model will use the GPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tokenize and Encode the comments and labels for the training set\ninput_ids, attention_masks, labels = tokenize_and_encode(\n    tokenizer,\n    train_data_cleaned,\n    train_labels_cleaned.values\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:37:39.033311Z","iopub.execute_input":"2024-10-21T12:37:39.034272Z","iopub.status.idle":"2024-10-21T12:41:52.661994Z","shell.execute_reply.started":"2024-10-21T12:37:39.034227Z","shell.execute_reply":"2024-10-21T12:41:52.660717Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Tokenize and Encode the comments and labels for the validation set\nval_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n    tokenizer,\n    val_data_cleaned,\n    val_labels_cleaned.values\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:41:52.663498Z","iopub.execute_input":"2024-10-21T12:41:52.663842Z","iopub.status.idle":"2024-10-21T12:42:54.607294Z","shell.execute_reply.started":"2024-10-21T12:41:52.663808Z","shell.execute_reply":"2024-10-21T12:42:54.606224Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print('Training Comments :',train_data_cleaned.shape)\nprint('Input Ids         :',input_ids.shape)\nprint('Attention Mask    :',attention_masks.shape)\nprint('Labels            :',labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:54.608543Z","iopub.execute_input":"2024-10-21T12:42:54.608884Z","iopub.status.idle":"2024-10-21T12:42:54.615063Z","shell.execute_reply.started":"2024-10-21T12:42:54.608852Z","shell.execute_reply":"2024-10-21T12:42:54.614042Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Training Comments : (127649,)\nInput Ids         : torch.Size([127649, 512])\nAttention Mask    : torch.Size([127649, 512])\nLabels            : torch.Size([127649, 6])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check an encoded text with the corresponding text and labels (e.g., comment #25)\ni = 25\nprint('Example comment:',train_data_cleaned.values[i])\nprint('\\nInput Ids:\\n',input_ids[i])\nprint('\\nDecoded Ids:\\n',tokenizer.decode(input_ids[i]))\nprint('\\nAttention Mask:\\n',attention_masks[i])\nprint('\\nLabels:',labels[i])","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:54.616304Z","iopub.execute_input":"2024-10-21T12:42:54.616721Z","iopub.status.idle":"2024-10-21T12:42:54.642859Z","shell.execute_reply.started":"2024-10-21T12:42:54.616679Z","shell.execute_reply":"2024-10-21T12:42:54.641995Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Example comment: you, and no one else, have explained why this one word is vandalism. it cetainly appiles to him, and you are now saying that people have to decide wheter it applies by some sort of vote that is certainly not neutrality. on what basis is this word vanalism\n\nInput Ids:\n tensor([    2,    42,    15,    17,    90,    53,   962,    15,    57,  2897,\n          483,    48,    53,   833,    25, 29359,     9,    32,  4000,  5851,\n          102,  4865,  3599,    18,    20,    61,    15,    17,    42,    50,\n          130,  1148,    30,   148,    57,    20,  4073, 11153, 12382,    32,\n        13169,    34,   109,  2058,    16,  2018,    30,    25,  3850,    52,\n        23079,     9,    27,    98,  2239,    25,    48,   833,  1019,   192,\n          756,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\n\nDecoded Ids:\n [CLS] you, and no one else, have explained why this one word is vandalism. it cetainly appiles to him, and you are now saying that people have to decide wheter it applies by some sort of vote that is certainly not neutrality. on what basis is this word vanalism[SEP]<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n\nAttention Mask:\n tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\n\nLabels: tensor([0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\n\n# Creating DataLoader\nbatch_size = 8\n\n# Training set\ntrain_dataset = TensorDataset(input_ids, attention_masks, labels)\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n# Validation set\nval_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:54.644040Z","iopub.execute_input":"2024-10-21T12:42:54.644321Z","iopub.status.idle":"2024-10-21T12:42:54.649901Z","shell.execute_reply.started":"2024-10-21T12:42:54.644291Z","shell.execute_reply":"2024-10-21T12:42:54.649053Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Check the train_loader data\nprint('Batch Size :',train_loader.batch_size)\nBatch = next(iter(train_loader))\nprint('Each Input ids shape :', Batch[0].shape)\nprint('Input ids :\\n', Batch[0][0])\nprint('Corresponding Decoded text:\\n', tokenizer.decode(Batch[0][0]))\nprint('Corresponding Attention Mask :\\n', Batch[1][0])\nprint('Corresponding Label:', Batch[2][0])","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:54.651096Z","iopub.execute_input":"2024-10-21T12:42:54.651411Z","iopub.status.idle":"2024-10-21T12:42:54.695607Z","shell.execute_reply.started":"2024-10-21T12:42:54.651381Z","shell.execute_reply":"2024-10-21T12:42:54.694717Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Batch Size : 8\nEach Input ids shape : torch.Size([8, 512])\nInput ids :\n tensor([    2,   107,    42,   196,   186,  1923,    20, 22061,    16,  2202,\n          464,   835,  3376,    19, 20169,   100,    86,    15,    98,   107,\n           42, 21717,    20,    44,    14,  1236,  2141,    26,   447,    16,\n          475,   993,  3376,     3,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\nCorresponding Decoded text:\n [CLS] do you see any value to consistency of treatment across similar articles in wikipedia if so, what do you perceive to be the standard approach for history of country x articles[SEP]<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\nCorresponding Attention Mask :\n tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])\nCorresponding Label: tensor([0, 0, 0, 0, 0, 0])\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.optim import AdamW\n\n# Optimizer setup\noptimizer = AdamW(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:54.696741Z","iopub.execute_input":"2024-10-21T12:42:54.697102Z","iopub.status.idle":"2024-10-21T12:42:55.146347Z","shell.execute_reply.started":"2024-10-21T12:42:54.697052Z","shell.execute_reply":"2024-10-21T12:42:55.145499Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Calculate label counts from the cleaned training dataset\nlabel_counts = train_labels_cleaned.sum(axis=0).values  # Sum the counts of each label\ntotal_count = len(train_labels_cleaned)  # Get the total number of samples\n\n# Calculate class weights\nclass_weights = total_count / (len(label_counts) * label_counts)\n\n# Create a DataFrame to display counts and weights\nclass_data = pd.DataFrame({\n    'Class': column_labels,\n    'Count': label_counts,\n    'Weight': class_weights\n})\n\n# Sort the DataFrame by 'Count' in descending order\nclass_data = class_data.sort_values(by='Count', ascending=False).reset_index(drop=True)\n\n# Display the DataFrame\nclass_data","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:55.147677Z","iopub.execute_input":"2024-10-21T12:42:55.148300Z","iopub.status.idle":"2024-10-21T12:42:55.165665Z","shell.execute_reply.started":"2024-10-21T12:42:55.148255Z","shell.execute_reply":"2024-10-21T12:42:55.164807Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"           Class  Count     Weight\n0          toxic  12238   1.738424\n1        obscene   6734   3.159316\n2         insult   6263   3.396908\n3   severe_toxic   1274  16.699241\n4  identity_hate   1111  19.149265\n5         threat    404  52.660479","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n      <th>Count</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>toxic</td>\n      <td>12238</td>\n      <td>1.738424</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>obscene</td>\n      <td>6734</td>\n      <td>3.159316</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>insult</td>\n      <td>6263</td>\n      <td>3.396908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>severe_toxic</td>\n      <td>1274</td>\n      <td>16.699241</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>identity_hate</td>\n      <td>1111</td>\n      <td>19.149265</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>threat</td>\n      <td>404</td>\n      <td>52.660479</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from torch import nn\n\n# Convert class_weights to a PyTorch tensor\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n# Update the loss function using class weights\nloss_fn = nn.BCEWithLogitsLoss(weight=class_weights_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:55.166796Z","iopub.execute_input":"2024-10-21T12:42:55.167440Z","iopub.status.idle":"2024-10-21T12:42:55.343036Z","shell.execute_reply.started":"2024-10-21T12:42:55.167398Z","shell.execute_reply":"2024-10-21T12:42:55.342180Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Function to train the model\ndef train_model_with_class_weights(model, train_loader, optimizer, device, num_epochs, loss_fn):\n        \n    # Loop through the specified number of epochs\n    for epoch in range(num_epochs):\n        model.train()  # Set the model to training mode\n        total_loss = 0  # Initialize total loss for the current epoch\n\n        # Loop through the batches in the training data\n        for i, batch in enumerate(train_loader):\n            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n\n            optimizer.zero_grad()  # Clear the gradients from the previous step to prevent accumulation\n            \n            # Model output        \n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            \n            # Convert labels to Float type\n            labels = labels.float().to(device)\n                        \n            # Calculate losses based on class weights        \n            loss = loss_fn(logits, labels)\n            total_loss += loss.item()\n            \n            # Backward error propagation        \n            loss.backward()\n            optimizer.step()\n            \n        # Clear GPU memory\n        torch.cuda.empty_cache()\n            \n        model.eval()  # Set the model to evaluation mode\n        val_loss = 0\n        \n        # Disable gradient computation during validation\n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids, attention_mask, labels = [t.to(device) for t in batch]\n\n                outputs = model(input_ids, attention_mask=attention_mask)\n                logits = outputs.logits\n                \n                # Convert labels to Float type\n                labels = labels.float().to(device)\n                \n                # Validation losses based on class weights\n                loss = loss_fn(logits, labels)\n                val_loss += loss.item()\n\n        # Print the average loss for the current epoch\n        print(f'Epoch {epoch+1}: ')\n        print(f'  Training Loss: {total_loss/len(train_loader)}')\n        print(f'  Validation Loss: {val_loss/len(val_loader)}')","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:55.344346Z","iopub.execute_input":"2024-10-21T12:42:55.345125Z","iopub.status.idle":"2024-10-21T12:42:55.355510Z","shell.execute_reply.started":"2024-10-21T12:42:55.345077Z","shell.execute_reply":"2024-10-21T12:42:55.354601Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model = nn.DataParallel(model)\nmodel.to(device)\n\n# Call the function to train the model\ntrain_model_with_class_weights(model, train_loader, optimizer, device, num_epochs=5, loss_fn=loss_fn)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T12:42:55.356821Z","iopub.execute_input":"2024-10-21T12:42:55.357443Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: \n  Training Loss: 0.3929167888973261\n  Validation Loss: 0.31966396892002147\nEpoch 2: \n  Training Loss: 0.30350104450868187\n  Validation Loss: 0.2871042797713655\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Test the model on the `test_cleaned` dataset","metadata":{}},{"cell_type":"code","source":"# Path to a clean test dataset\ntest_dataset_path = '/kaggle/input/toxic-comments/test_claud.csv'\n\n# Load the dataset into a DataFrame\ndf_test = pd.read_csv(test_dataset_path)\n\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract the comment texts and labels from the test DataFrame\ntest_data = df_test['comment_text']\ntest_labels = df_test.iloc[:, 2:]\n\nprint(f'Test data shape: {test_data.shape}')\nprint(f'Test labels shape: {test_labels.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sum the labels to get the total count for each class\nlabel_counts_test = test_labels.sum(axis=0)\n\n# Convert the NumPy array to a pandas Series\nlabel_counts_test = pd.Series(label_counts_test)\n\n# Sort the label counts in descending order\nlabel_counts_test = label_counts_test.sort_values(ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing the class distribution of the 'label' column\nplt.figure(figsize=(10, 6))\n\nax = sns.barplot(x=label_counts_test.index, y=label_counts_test.values, palette='pastel')\n\n# Add labels and title to the plot\nplt.xlabel('Labels')\nplt.ylabel('Number of Cases')\nplt.title('Distribution of Label Frequency for the Test Dataset')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for NaN values in test_data\nprint(\"NaN values in test_data:\")\nprint(test_data.isnull().sum())\n\n# Drop rows with NaN values in test_data\ntest_data_cleaned = test_data.dropna()\n\n# Filter test_labels to match the cleaned test_data\ntest_labels_cleaned = test_labels.loc[test_data_cleaned.index]\n\n# Recheck for NaN values after cleaning\nprint(\"NaN values in test_data_cleaned:\")\nprint(test_data_cleaned.isnull().sum())\nprint(\"NaN values in test_labels_cleaned:\")\nprint(test_labels_cleaned.isnull().sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize and Encode the comments and labels for the test set\ntest_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n    tokenizer,\n    test_data_cleaned,\n    test_labels_cleaned.values\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating DataLoader for the testing dataset\ntest_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\ndef evaluate_model(model, test_loader, device, label_names):\n    model.eval()  # Set the model to evaluation mode\n\n    true_labels = []  # List to store true labels\n    predicted_probs = []  # List to store predicted probabilities\n\n    # Disable gradient computation for evaluation\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n\n            # Get model's predictions\n            outputs = model(input_ids, attention_mask=attention_mask)\n            \n            # Apply sigmoid for multilabel classification to get probabilities\n            predicted_probs_batch = torch.sigmoid(outputs.logits)\n            predicted_probs.append(predicted_probs_batch.cpu().numpy())\n\n            # Store true labels for later evaluation\n            true_labels_batch = labels.cpu().numpy()\n            true_labels.append(true_labels_batch)\n\n    # Combine predictions and labels for evaluation\n    true_labels = np.concatenate(true_labels, axis=0)\n    predicted_probs = np.concatenate(predicted_probs, axis=0)\n\n    # Apply threshold for binary classification (0.5 is commonly used)\n    predicted_labels = (predicted_probs > 0.5).astype(int)\n\n    # Calculate evaluation metrics for overall performance\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    precision = precision_score(true_labels, predicted_labels, average='micro')\n    recall = recall_score(true_labels, predicted_labels, average='micro')\n    f1 = f1_score(true_labels, predicted_labels, average='micro')\n\n    # Calculate evaluation metrics for each label (class-specific)\n    precision_per_label = precision_score(true_labels, predicted_labels, average=None)\n    recall_per_label = recall_score(true_labels, predicted_labels, average=None)\n    f1_per_label = f1_score(true_labels, predicted_labels, average=None)\n\n    # Print the overall evaluation metrics\n    print(f'Overall Accuracy: {accuracy:.4f}')\n    print(f'Overall Precision: {precision:.4f}')\n    print(f'Overall Recall: {recall:.4f}')\n    print(f'Overall F1 Score: {f1:.4f}')\n\n    # Print evaluation metrics for each label\n    print(\"\\nEvaluation per label:\")\n    for i, label in enumerate(label_names):\n        print(f'{label}:')\n        print(f'  Precision: {precision_per_label[i]:.4f}')\n        print(f'  Recall: {recall_per_label[i]:.4f}')\n        print(f'  F1 Score: {f1_per_label[i]:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of labels in the dataset\nlabel_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\n# Call the function to evaluate the model on the test data\nevaluate_model(model, test_loader, device, label_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the model","metadata":{}},{"cell_type":"code","source":"import os\n\n# Define the output directory for the model and tokenizer\noutput_dir = \"/kaggle/working/toxic_albert_model\"\n\n# Save the model's state dictionary and configuration\nmodel.save_pretrained(output_dir)\nprint(f\"Model configuration saved to: {os.path.join(output_dir, 'config.json')}\")\n\n# Save the tokenizer's configuration and vocabulary\ntokenizer.save_pretrained(output_dir)\nprint(f\"Tokenizer configuration and vocabulary saved to: {output_dir}\")\n\n# Save the model weights separately\nweights_path = os.path.join(output_dir, 'toxic_albert_model_weights.pth')\ntorch.save(model.state_dict(), weights_path)\nprint(f\"Model weights saved to: {weights_path}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from safetensors.torch import save_file\n\n# Save the model in safetensors format\nsafetensors_path = os.path.join(output_dir, 'model.safetensors')\nsave_file(model.state_dict(), safetensors_path)\nprint(f\"Model saved in Safetensors format at: {safetensors_path}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a dictionary to hold both the model's state dict and the tokenizer\nmodel_data = {\n    'model_state_dict': model.state_dict(),\n    'tokenizer_config': tokenizer,\n}\n\n# Save the entire model and tokenizer as a single .pt file\npt_file_path = os.path.join(output_dir, 'toxic_albert_model.pt')\ntorch.save(model_data, pt_file_path)\n\nprint(f\"Model and tokenizer saved as a single .pt file at: {pt_file_path}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# Save the entire model using Pickle\npickle_path = os.path.join(output_dir, 'toxic_albert_model.pkl')\nwith open(pickle_path, 'wb') as fh:\n    pickle.dump(model, fh)\n\nprint(f\"Model saved as a Pickle file at: {pickle_path}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}