{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNjexT5mf9GoiqoB0eKosO7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVWZeqCzLdz5","executionInfo":{"status":"ok","timestamp":1728840687557,"user_tz":-120,"elapsed":23416,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"4610921c-bfcf-4940-ecb1-b964436ec3ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["name_df = \"train_claud_2_0\"\n","\n","train_df = f'/content/drive/MyDrive/data/{name_df}.csv'\n","\n","train_df = pd.read_csv(train_df)\n","\n","train_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCVvIB49LxF0","executionInfo":{"status":"ok","timestamp":1728842852280,"user_tz":-120,"elapsed":1822,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"5028fb37-a5ec-47a4-99ef-39e601f1b1bd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 158728 entries, 0 to 158727\n","Data columns (total 9 columns):\n"," #   Column         Non-Null Count   Dtype \n","---  ------         --------------   ----- \n"," 0   id             158728 non-null  object\n"," 1   comment_text   158728 non-null  object\n"," 2   toxic          158728 non-null  int64 \n"," 3   severe_toxic   158728 non-null  int64 \n"," 4   obscene        158728 non-null  int64 \n"," 5   threat         158728 non-null  int64 \n"," 6   insult         158728 non-null  int64 \n"," 7   identity_hate  158728 non-null  int64 \n"," 8   token_count    158728 non-null  int64 \n","dtypes: int64(7), object(2)\n","memory usage: 10.9+ MB\n"]}]},{"cell_type":"markdown","source":["# Цей код реалізує повний процес навчання та використання моделі класифікації токсичності на основі BERT. Ось короткий опис основних компонентів:\n","\n","Завантаження та підготовка даних\n","Створення користувацького класу Dataset для роботи з даними\n","Ініціалізація токенізатора BERT та моделі для класифікації послідовностей\n","Створення DataLoader для ефективного завантаження даних\n","Налаштування оптимізатора та функції втрат\n","Функції для навчання та оцінки моделі\n","Цикл навчання моделі\n","Збереження навченої моделі\n","Функція для прогнозування токсичності нових коментарів\n","\n","Цей код надає вам основу для роботи з проектом. Ви можете адаптувати його відповідно до ваших конкретних потреб, наприклад, змінити гіперпараметри, додати валідацію або реалізувати додаткові функції.\n","Чи хотіли б ви, щоб я детальніше пояснив якусь частину коду або надав додаткову інформацію про певні аспекти проекту?"],"metadata":{"id":"2Q_-b1FEO_0g"}},{"cell_type":"code","source":["import torch\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from sklearn.model_selection import train_test_split\n","\n","# Завантаження та підготовка даних\n","df = train_df\n","texts = df['comment_text'].values\n","labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n","\n","# Розділення на тренувальний та тестовий набори\n","train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n","\n","# Клас для створення набору даних\n","class ToxicityDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        text = str(self.texts[item])\n","        label = self.labels[item]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        return {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.FloatTensor(label)\n","        }\n","\n","# Ініціалізація токенізатора та моделі\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)\n","\n","# Створення наборів даних\n","train_dataset = ToxicityDataset(train_texts, train_labels, tokenizer, max_len=256)\n","val_dataset = ToxicityDataset(val_texts, val_labels, tokenizer, max_len=256)\n","\n","# Створення завантажувачів даних\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32)\n","\n","# Налаштування оптимізатора та функції втрат\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","loss_fn = torch.nn.BCEWithLogitsLoss()\n","\n","# Функція для навчання моделі\n","def train_epoch(model, data_loader, loss_fn, optimizer, device):\n","    model.train()\n","    losses = []\n","    for batch in data_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        loss = loss_fn(outputs.logits, labels)\n","        losses.append(loss.item())\n","\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    return np.mean(losses)\n","\n","# Функція для оцінки моделі\n","def eval_model(model, data_loader, loss_fn, device):\n","    model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            loss = loss_fn(outputs.logits, labels)\n","            losses.append(loss.item())\n","\n","    return np.mean(losses)\n","\n","# Навчання моделі\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","epochs = 3\n","for epoch in range(epochs):\n","    print(f'Epoch {epoch + 1}/{epochs}')\n","    train_loss = train_epoch(model, train_loader, loss_fn, optimizer, device)\n","    print(f'Train loss: {train_loss}')\n","    val_loss = eval_model(model, val_loader, loss_fn, device)\n","    print(f'Val loss: {val_loss}')\n","    print('-' * 10)\n","\n","\n","# Створіть папку для збереження моделі, якщо вона ще не існує\n","save_path = '/content/drive/My Drive/toxicity_model'\n","os.makedirs(save_path, exist_ok=True)\n","\n","# Збереження моделі\n","torch.save(model.state_dict(), os.path.join(save_path, 'toxicity_model.pth'))\n","print(f\"Модель збережено на Google Drive у папці: {save_path}\")\n","\n","# # Додайте код для завантаження моделі (для майбутнього використання)\n","# def load_model(model, path):\n","#     model.load_state_dict(torch.load(path))\n","#     return model\n","\n","# Приклад завантаження моделі\n","# loaded_model = load_model(BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6), os.path.join(save_path, 'toxicity_model.pth'))\n","\n","# Функція для прогнозування токсичності\n","def predict_toxicity(text):\n","    encoding = tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=256,\n","        return_token_type_ids=False,\n","        padding='max_length',\n","        truncation=True,\n","        return_attention_mask=True,\n","        return_tensors='pt',\n","    )\n","\n","    input_ids = encoding['input_ids'].to(device)\n","    attention_mask = encoding['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        predictions = torch.sigmoid(outputs.logits)\n","\n","    return predictions.cpu().numpy()[0]\n","\n","# # Приклад використання\n","# sample_text = \"You are an idiot!\"\n","# toxicity_scores = predict_toxicity(sample_text)\n","# print(f\"Токсичність коментаря '{sample_text}':\")\n","# print(f\"Toxic: {toxicity_scores[0]:.4f}\")\n","# print(f\"Severe Toxic: {toxicity_scores[1]:.4f}\")\n","# print(f\"Obscene: {toxicity_scores[2]:.4f}\")\n","# print(f\"Threat: {toxicity_scores[3]:.4f}\")\n","# print(f\"Insult: {toxicity_scores[4]:.4f}\")\n","# print(f\"Identity Hate: {toxicity_scores[5]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqrgfdbLMHmv","executionInfo":{"status":"ok","timestamp":1728860431598,"user_tz":-120,"elapsed":17344938,"user":{"displayName":"Maksim","userId":"18160881988083746316"}},"outputId":"9696c597-715c-45d4-d941-667e5e837992"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","Train loss: 0.05264688588394149\n","Val loss: 0.040243079591167796\n","----------\n","Epoch 2/3\n","Train loss: 0.0356082279573914\n","Val loss: 0.038559928578473505\n","----------\n","Epoch 3/3\n","Train loss: 0.02784090594916476\n","Val loss: 0.044184952334738604\n","----------\n","Модель збережено на Google Drive у папці: /content/drive/My Drive/toxicity_model\n"]}]}]}